---
title: 分布式
author: Shaun
date: 2020-07-11 10:33:00 +0800
categories: [面试题]
tags: [jvm]
math: true
mermaid: true
---

> 分布式系统是一个硬件或软件组件分布在不同的网络计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统。
{: .prompt-tip }

## 发展历程

- 入口级负载均衡
    - 网关负载均衡
    - 客户端负载均衡

- 单应用架构
    - 应用服务和数据服务分离
    - 应用服务集群
    - 应用服务中心化SAAS

- 数据库主备读写分离
    - 全文搜索引擎加快数据统计
    - 缓存集群缓解数据库读压力
    - 分布式消息中间件缓解数据库写压力
    - 数据库水平拆分适应微服务
    - 数据库垂直拆分解决慢查询

- 划分上下文拆分微服务
    - 服务注册发现（Eureka、Nacos）
    - 配置动态更新（Config、Apollo）
    - 业务灰度发布（Gateway、Feign）
    - 统一安全认证（Gateway、Auth）
    - 服务降级限流（Hystrix、Sentinel）
    - 接口检查监控（Actuator、Prometheus）
    - 服务全链路追踪（Sleuth、Zipkin）


## CAP

- **一致性**（2PC、3PC、Paxos、Raft）
    - 强一致性：
        - **数据库一致性**，牺牲了性能
        - **ACID**：原子性、一致性、隔离性、持久性
    - 弱一致性：
        - **数据库和缓存**
        - **延迟双删**
        - **重试**
    - 单调读一致性：
        - **缓存一致性**
        - ID或者IP哈希
    - 最终一致性
        - **边缘业务**
        - 消息队列
- 可用性（多级缓存、读写分离）
    - **BASE** 基本可用：限流导致响应速度慢、降级导致用户体验差
        - Basically Availabe 基本可用 
        - Soft state 软状态
        - Eventual Consistency 最终一致性
- 分区容忍性（一致性Hash解决扩缩容问题）

## 一致性

### XA 方案

**2PC**协议：两阶段提交协议，P 是指**准备**阶段，C是指**提交**阶段
- 准备阶段：询问是否可以开始，写Undo、Redo日志，收到响应；
- 提交阶段：执行Redo日志进行Commit，执行Undo日志进行Rollback；

**3PC**协议：将提交阶段分为**CanCommit、PreCommit、DoCommit**三个阶段
- **CanCommit**：发送canCommit请求，并开始等待；
- **PreCommit**：收到全部Yes，写Undo、Redo日志。超时或者No，则中断；
- **DoCommit**：执行Redo日志进行**Commit**，执行Undo日志进行**Rollback**；

区别是第二步，参与者**自身增加了超时，如果失败可以及时释放资源**。

### Paxos 算法

> 如何在一个发生异常的分布式系统中，快速且正确地在集群内部对某个数据的值达成一致。

参与者（例如Kafka）的一致性可以由协调者（例如Zookeeper）来保证，协调者的一致性就只能
由Paxos保证了

Paxos算法中的角色：
- `Client`：客户端、例如，对分布式文件服务器中文件的写请求。
- `Proposer`：提案发起者，根据Accept返回选择最大N对应的V，发送[N+1,V]
- `Acceptor`：决策者，Accept以后会拒绝小于N的提案，并把自己的[N,V]返回给Proposer
- `Learners`：最终决策的学习者、学习者充当该协议的复制因素

算法约束P1：
- 一个Acceptor必须接受它收到的第一个提案。
- 考虑到半数以上才作数，一个Accpter得接受多个相同v的提案P2a:如果某个v的提案被accept，那么被Acceptor接受编号更高的提案必须也是vP2b:如果某个v的提案被accept，那么从Proposal提出编号更高的提案必须也是v
- 如何确保v的提案Accpter被选定后，Proposal都能提出编号更高的提案呢针对任意的[Mid,Vid]，有半数以上的Accepter集合S，满足以下二选一：S中接受的提案都大于Mid  S中接受的提案若小于Mid，编号最大的那个值为Vid

#### Q1：面试题：如何保证Paxos算法活性

假设存在这样一种极端情况，有两个Proposer依次提出了一系列编号递增的提案，导致最终陷入死循环，没有value被选定：

- **通过选取主Proposer**，规定只有主Proposer才能提出议案。只要主Proposer和过半的Acceptor能够正常网络通信，主Proposer提出一个编号更高的提案，该提案终将会被批准；

- 每个Proposer发送提交提案的时间设置为**一段时间内随机**，保证不会一直死循环；

### Raft算法
> Raft 是一种为了管理复制日志的一致性算法

Raft使用**心跳机制**来触发选举。当server启动时，初始状态都是**follower**。每一个
server都有一个定时器，超时时间为election timeout（**一般为150-300ms）**，如果某
server**没有超时的情况下**收到来自领导者或者候选者的任何消息，**定时器重启**，如果
超时，它就**开始一次选举**。

- **Leader异常**：异常期间Follower会超时选举，完成后Leader比较彼此步长

- **Follower异常**：恢复后直接同步至Leader当前状态

- **多个Candidate**：选举时失败，失败后超时继续选举

### 数据库和Redis的一致性

全量缓存保证高效读取。

所有数据都存储在缓存里，读服务在查询时不会再降级到数据库里，所有的请求都完全依赖缓存。
此时，因降级到数据库导致的毛刺问题就解决了。但全量缓存并**没有解决更新时的分布式事务**
问题，反而把问题放大了。因为全量缓存**对数据更新要求更加严格**，要求所有数据库
**已有数据和实时更新**的数据必须完全同步至缓存，不能有遗漏。对于此问题，一种有效的方案
是采用**订阅数据库的 Binlog** 实现数据同步。

现在很多开源工具（如阿里的 Canal等）可以模拟主从复制的协议。通过模拟协议读取主数据库
的 Binlog 文件，从而获取主库的所有变更。对于这些变更，它们开放了各种接口供业务服务获
取数据。

将 Binlog 的中间件挂载至目标数据库上，就可以**实时获取该数据库的所有变更数据**。对这
些变更数据解析后，便可**直接写入缓存里**。优点还有：
- 大幅提升了读取的速度，降低了延迟；
- Binlog 的主从复制是基于 **ACK** 机制， 解决了分布式事务的问题；
如果同步缓存失败了，被消费的 Binlog 不会被确认，下一次会重复消费，数据最终会写入缓存中；

**缺点**不可避免：
1. 增加复杂度
2. 消耗缓存资源
3. 需要筛选和压缩数据
4. 极端情况数据丢失；

### 可用性
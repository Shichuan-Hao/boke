---
title: 虚拟内存
author:
  name: superhsc
  link: https://github.com/maxpixelton
date: 2020-06-24 21:33:35 +0800
categories: [计算机基础, 操作系统]
tags: [虚拟内存]
math: true
mermaid: true
---

内存是稀缺的，随着应用使用内存也在膨胀。当程序越来复杂，进程对内存的需求会越来越大。从安全角度考虑，进程间使用内存需要隔离。另外还有一些特殊场景，比如说：内存一致性问题，存在不希望 CPU 进行缓存的场景。 这个时候，有一个虚拟化层承接各种各样的诉求，统一进行处理，就会有很大的优势。

### 内存不够用的原因

要理解一个技术，就必须理解它为何而存在。

总体来说，**虚拟化技术是为了解决内存不够用的问题**，那么内存为何不够用呢？主要是因为程序越来越复杂。

比如说我现在的电脑中有 200 个进程，目前内存的消耗是 21G，我的内存是 64G 的，但是多开一些程序还是会被占满。 另外，如果一个程序需要使用大的内存，比如 1T，是不是应该报错？如果报错，那么程序就会不好写，程序员必须小心翼翼地处理内存的使用，避免超过允许的内存使用阈值。以上提到的这些都是需要解决的问题，也是虚拟化技术存在的价值和意义。

如何来解决这些问题呢？ 历史上有过不少的解决方案，但最终沉淀下的是虚拟化技术。

#### 交换（Swap）技术

Swap 技术允许一部分进程使用内存，不使用内存的进程数据先保存在磁盘上。

注意，这里提到的数据，是完整的进程数据，包括正文段（程序指令）、数据段、堆栈段等。

轮到某个进程执行的时候，尝试为这个进程在内存中找到一块空闲的区域。如果空间不足，就考虑把没有在执行的进程交换（Swap）到磁盘上，把空间腾挪出来给需要的进程。

![This is a image](https://maxpixelton.github.io/images/assert/os/2401.png)'

上图中，内存被拆分成多个区域。 内核作为一个程序也需要自己的内存。

另外每个进程独立得到一个空间——称为地址空间（**Address Space）**。可以认为地址空间是一块连续分配的内存块。每个进程在不同地址空间中工作，构成了一个原始的虚拟化技术。

比如：当进程 A 想访问地址 100 的时候，实际上访问的地址是基于地址空间本身位置（首字节地址）计算出来的。另外，当进程 A 执行时，CPU 中会保存它地址空间的开始位置和结束位置，当它想访问超过地址空间容量的地址时，CPU 会检查然后报错。

上图描述的这种方法，是一种比较**原始的虚拟化技术，**进程使用的是基于地址空间的虚拟地址。但是这种方案有很多明显的缺陷，比如：

1. **碎片问题**：上图中看到进程来回分配、回收交换，内存之间会产生很多缝隙。经过反反复复使用，内存的情况会变得十分复杂，导致整体性能下降。
2. **频繁切换问题**：如果进程过多，内存较小，会频繁触发交换。

重新 Review 下设计目标。

1. 隔离：每个应用有自己的地址空间，互不影响。
2. 性能：高频使用的数据保留在内存中、低频使用的数据持久化到磁盘上。
3. 程序好写（降低程序员心智负担）：让程序员不用关心底层设施。

现阶段：

- 关于问题 1，Swap 技术已经初步解决了；
- 关于问题 2，Swap 技术在性能上存在着碎片、频繁切换等明显劣势；
- 关于问题 3，使用 Swap 技术，程序员需要清楚地知道自己的应用用多少内存，并且小心翼翼地使用内存，避免需要重新申请，或者研发不断扩容的算法——这让程序心智负担较大。

经过以上分析，需要更好的解决方案，就是虚拟化技术。

#### 虚拟内存

在虚拟化技术中，操作系统设计了虚拟内存（理论上可以无限大的空间），受限于 CPU 的处理能力，通常 64bit CPU，就是 $2^{64}$ 个地址。

![This is a image](https://maxpixelton.github.io/images/assert/os/2402.png)

虚拟化技术中，应用使用的是虚拟内存，操作系统管理虚拟内存和真实内存之间的映射。

操作系统将虚拟内存分成整齐小块，每个小块称为一个**页（Page）**。之所以这样做，原因主要有以下两个方面：

- 一方面应用使用内存是以页为单位，整齐的页能够避免内存碎片问题‘；
- 另一方面，每个应用都有**高频使用的数据**和**低频使用的数据**。这样做，操作系统就不必从应用角度去思考哪个进程是高频的，仅需思考哪些页被高频使用、哪些页被低频使用。如果是低频使用，就将它们保存到硬盘上；如果是高频使用，就让它们保留在真实内存中。

如果一个应用需要非常大的内存，应用申请的是虚拟内存中的很多个页，真实内存不一定需要够用。

### 页（Page）和页表

操作系统将虚拟内存分块，每个小块称为一个页（Page）；

真实内存也需要分块，每个小块称为一个 Frame。Page 到 Frame 的映射，需要一种叫作页表的结构。

![This is a image](https://maxpixelton.github.io/images/assert/os/2403.png)

上图展示了 **Page**、**Frame** 和**页表 （PageTable）**三者之间的关系。 

Page 大小和 Frame 大小通常相等，页表中记录的某个 Page 对应的 Frame 编号。页表也需要存储空间，比如：

- 虚拟内存大小为 10G， Page 大小是 4K，那么需要 $10G \div 4K= 2621440 $ $  个条目。如果每个条目是 64bit，那么一共需要 20480K = 20M 页表。操作系统在内存中划分出小块区域给页表，并负责维护页表。

页表维护了虚拟地址到真实地址的映射。每次程序使用内存时，需要把虚拟内存地址换算成物理内存地址，换算过程分为以下 3 个步骤：

1. 通过虚拟地址计算 Page 编号；
2. 查页表，根据 Page 编号，找到 Frame 编号；
3. 将虚拟地址换算成物理地址。

详细换算的过程：如果页大小是 4K，假设程序要访问地址：100,000。那么计算过程如下。

1. 页编号（Page Number） = 100,000/4096 = 24 **余**1619。 24 是页编号，1619 是地址偏移量（Offset）。
2. 查询页表，得到 24 关联的 Frame 编号（假设查到 Frame 编号 = 10）。
3. 换算：通常 Frame 和 Page 大小相等，替换 Page Number 为 Frame Number 物理地址 = 4096 * 10 + 1619 = 42579。

#### MMU

上面的过程发生在 CPU 中一个小型的设备——内存管理单元（Memory Management Unit， MMU）中。如下图所示：

![This is a image](https://maxpixelton.github.io/images/assert/os/2404.png)

当 CPU 需要执行一条指令时，如果指令中涉及内存读写操作，CPU 会把虚拟地址给 MMU，MMU 自动完成虚拟地址到真实地址的计算；然后，MMU 连接了地址总线，帮助 CPU 操作真实地址。

这样的设计，不需要在编写应用程序时担心虚拟地址到物理地址映射的问题。把全部难题都丢给了操作系统——操作系统要确定 MMU 可以读懂自己的页表格式。所以，操作系统的设计者要看 MMU 的说明书完成工作。

难点在于不同 CPU 的 MMU 可能是不同的，因此这里会遇到很多跨平台的问题。解决跨平台问题不但有繁重的工作量，更需要高超的编程技巧，Unix 最初期的移植性（跨平台）是 C 语言作者丹尼斯·里奇实现的。

#### 页表条目

页表中的每一项（**页表条目**）长什么样子呢？下图是一个页表格式的一个演示。

![This is a image](https://maxpixelton.github.io/images/assert/os/2405.png)

页表条目本身编号可以不存在页表中，而是通过偏移量计算。 比如地址 100,000 的编号，可以用 100,000 除以页大小确定：

- **Absent（“在”）位，**是一个 bit。0 表示页的数据在磁盘中（不再内存中），1 表示在内存中。如果读取页表发现 Absent = 0，那么会触发缺页中断，去磁盘读取数据。
- **Protection（保护），**可以实现成 3 个 bit，它决定页表用于读、写、执行。比如 000 代表什么都不能做，100 代表只读等。
- **Reference（访问）位**，代表这个页被读写过，这个记录对回收内存有帮助。
- **Dirty（“脏”）位，**代表页的内容被修改过，如果 Dirty =1，那么意味着页面必须回写到磁盘上才能置换（Swap)。如果 Dirty = 0，如果需要回收这个页，可以考虑直接丢弃它（什么也不做，其他程序可以直接覆盖）。
- **Caching（缓存位），**描述页可不可以被 CPU 缓存。CPU 缓存会造成内存不一致问题，在上个模块的加餐中我们讨论了内存一致性问题，具体你可以参考“**模块四**”的加餐内容。
- **Frame Number（Frame 编号），**这个是真实内存的位置。用 Frame 编号乘以页大小，就可以得到 Frame 的基地址。

在 64bit 的系统中，考虑到 Absent、Protection 等字段需要占用一定的位，因此不能将 64bit 都用来描述真实地址。但是 64bit 可以寻址的空间已经远远超过了 EB 的级别（1EB = 220TB），这已经足够了。在真实世界，我们还造不出这么大的内存呢。

### 大页面问题

假设有一个应用，初始化后需要 12M 内存，操作系统页大小是 4K。那么应该如何设计呢？

为了简化模型，下图中，假设这个应用只有 3 个区域（3 个段）——正文段（程序）、数据段（常量、全局变量）、堆栈段。一开始 3 个段都分配了 4M 的空间。随着程序执行，堆栈段的空间会继续增加，上不封顶。

![This is a image](https://maxpixelton.github.io/images/assert/os/2406.png)

上图中，进程内部需要一个页表存储进程的数据。如果进程的内存上不封顶，那么页表有多少个条目合适呢？ 进程分配多少空间合适呢？ 如果页表大小为 1024 个条目，那么可以支持 1024*4K = 4M 空间。按照这个计算，如果进程需要 1G 空间，则需要 256K 个条目。我们预先为进程分配这 256K 个条目吗？ 创建一个进程就划分这么多条目是不是成本太高了？

为了减少条目的创建，可以考虑进程内部用一个更大的页表（比如 4M），操作系统继续用 4K 的页表。这就形成了一个二级页表的结构，如下图所示：

![This is a image](https://maxpixelton.github.io/images/assert/os/2407.png)

这样 MMU 会先查询 1 级页表，再查询 2 级页表。在这个模型下，进程如果需要 1G 空间，也只需要 1024 个条目。比如 1 级页编号是 2， 那么对应 2 级页表中 [2* 1024, 3*10241] 的部分条目。而访问一个地址，需要同时给出一级页编号和二级页编号。整个地址，还可以用 64bit 组装，如下图所示：

![This is a image](https://maxpixelton.github.io/images/assert/os/2408.png)

MMU 根据 1 级编号找到 1 级页表条目，1 级页表条目中记录了对应 2 级页表的位置。然后 MMU 再查询 2 级页表，找到 Frame。最后通过地址偏移量和 Frame 编号计算最终的物理地址。这种设计是一个递归的过程，因此还可增加 3 级、4 级……每增加 1 级，对空间的利用都会提高——当然也会带来一定的开销。这对于大应用非常划算，比如需要 1T 空间，那么使用 2 级页表，页表的空间就节省得多了。而且，这种多级页表，顶级页表在进程中可以先只创建需要用到的部分，就这个例子而言，一开始只需要 3 个条目，从 256K 个条目到 3 个，这就大大减少了进程创建的成本。

### 总结

>  一个程序最多能使用多少内存？
>
> 目前主要都是在用 64bit 的机器。因为 264 数字过于大，即便是虚拟内存都不需要这么大的空间。因此通常操作系统会允许进程使用非常大，但是不到 264 的地址空间。通常是几十到几百 EB（1EB = 106TB = 109GB)。



> 可不可以利用哈希表直接将页编号映射到 Frame 编号？
>
> 按照普通页表的设计，如果页大小是 4K，1G 空间内存需要 262144 个页表条目，如果每个条目用 4 个字节来存储，就需要 1M 的空间。那么创建 1T 的虚拟内存，就需要 1G 的空间。这意味着操作系统需要在启动时，就把这块需要的内存空间预留出来。
>
> 正因为设计的虚拟内存往往大于实际的内存，因此在历史上**出现过各种各样节省页表空间的方案，其中就有用 HashTable 存储页表的设计。HashTable 是一种将键（Key）映射到值（Value）的数据结构。在页表的例子中，键是页编号，值是 Frame 编号。 可以把这个 HashTable 看作存储了很多 <PageId, FrameId> 键值对的数据结构。**
>
> 下图使用了一个有 1024 个条目的 HashTable。当查找页面 50000 的时候，先通过哈希函数 h 计算出 50000 对应的 HashTable 条目是 24。HashTable 的每个条目都是一个链表，链表的每个节点是一个 PageId 和 FrameId 的组合。接下来，算法会遍历条目 24 上的链表，然后找到 Page = 50000 的节点。取出 Frame 编号为 1232。
>
> ![This is a image](https://maxpixelton.github.io/images/assert/os/thinking-2401.png)
>
> 通常虚拟内存会有非常多的页，但是只有少数的页会被使用到。这种情况下，用传统的页表，会导致过多的空间被预分配。而基于 HashTable 的设计则不同，可以先分配少量的项，比如在上图中，先只分配了 1024 个项。每次查找一个页表编号发现不存在的情况，再去对应位置的链表中添加一个具体的键值对。 这样就大大节省了内存。
>
> 当然节省空间也是有代价的，这会直接导致性能下降，因为比起传统页表我们可以直接通过页的编号知道页表条目，基于 HashTable 的做法需要先进行一次 Hash 函数的计算，然后再遍历一次链表。 最后，HashTable 的时间复杂度可以看作 O(k)，k 为 HashTable 表中总共的 <k,v> 数量除以哈希表的条目数。当 k 较小的时候 HashTable 的时间复杂度趋向于 O(1)。